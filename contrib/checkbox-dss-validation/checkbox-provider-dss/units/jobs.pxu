id: dss/initialize
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires:
  executable.name == 'dss'
_summary: Check that the DSS environment initializes
estimated_duration: 2m
command:
  set -eo pipefail
  KUBECONFIG="$(cat ~/.kube/config)"
  run_dss.sh initialize --kubeconfig "$KUBECONFIG"

id: dss/namespace
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires: executable.name == 'kubectl'
depends: dss/initialize
_summary: Check that the dss namespace is deployed
estimated_duration: 5s
command: kubectl get ns dss

id: dss/status_mlflow
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires: executable.name == 'dss'
depends: dss/namespace
_summary: Check that the dss mlflow is deployed
estimated_duration: 5s
command:
  set -eo pipefail
  run_dss.sh status | grep "MLflow deployment: Ready"

id: dss/create_pytorch_cpu_notebook
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires: executable.name == 'dss'
depends: dss/initialize
_summary: Check that an PyTorch CPU notebook can be successfully created
estimated_duration: 5m
command: timeout 5m run_dss.sh create pytorch-cpu --image=pytorch

id: cpu/pytorch_can_use_cpu
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires: executable.name == 'kubectl'
depends: dss/create_pytorch_cpu_notebook
_summary: Check that PyTorch can use CPU in notebook
estimated_duration: 1m
command: check_notebook.py pytorch-cpu has_pytorch_available

id: dss/remove_pytorch_cpu_notebook
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires: executable.name == 'dss'
depends: dss/create_pytorch_cpu_notebook
_summary: Check that the PyTorch CPU notebook can be removed
estimated_duration: 1m
command: run_dss.sh remove pytorch-cpu

id: dss/create_tensorflow_cpu_notebook
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires: executable.name == 'dss'
depends: dss/initialize
_summary: Check that an Tensorflow CPU notebook can be successfully created
estimated_duration: 5m
command: timeout 5m run_dss.sh create tensorflow-cpu --image=tensorflow

id: cpu/tensorflow_can_use_cpu
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires: executable.name == 'kubectl'
depends: dss/create_tensorflow_cpu_notebook
_summary: Check that Tensorflow can use CPU in notebook
estimated_duration: 1m
command: check_notebook.py tensorflow-cpu has_tensorflow_available

id: dss/remove_tensorflow_cpu_notebook
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires: executable.name == 'dss'
depends: dss/create_tensorflow_cpu_notebook
_summary: Check that the Tensorflow CPU notebook can be removed
estimated_duration: 1m
command: run_dss.sh remove tensorflow-cpu

# Intel XPU jobs ##############################################################

id: intel_gpu_plugin/install
category_id: dss-regress
flags: simple
imports:
  from com.canonical.certification import executable
  from com.canonical.certification import graphics_card
requires:
  graphics_card.vendor == 'Intel Corporation'
  executable.name == 'kubectl'
depends: dss/initialize
_summary: Install Intel K8s GPU Device Plugin
estimated_duration: 2m
command: check_intel.sh gpu_plugin_can_be_installed

id: intel_gpu_plugin/daemonset_name
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires: executable.name == 'microk8s'
depends: intel_gpu_plugin/install
_summary: Check that Intel GPU plugin daemonset is deployed
estimated_duration: 5s
command: check_intel.sh gpu_plugin_daemonset_is_deployed

id: intel_gpu_plugin/daemonset_number_available
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires: executable.name == 'microk8s'
depends: intel_gpu_plugin/install
_summary: Check that at least one Intel GPU daemonset is available
estimated_duration: 5s
command: check_intel.sh one_daemonset_is_available

id: intel_gpu_plugin/daemonset_number_ready
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires: executable.name == 'microk8s'
depends: intel_gpu_plugin/daemonset_number_available
_summary: Check that at least one Intel GPU daemonset is ready
estimated_duration: 5s
command: check_intel.sh one_daemonset_is_ready

id: intel_gpu_plugin/labels
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires: executable.name == 'microk8s'
depends: intel_gpu_plugin/daemonset_number_ready
_summary: Check that Kubernetes has label intel.feature.node.kubernetes.io/gpu
estimated_duration: 5s
command: check_intel.sh gpu_node_label_is_attached

id: intel_gpu_plugin/gpu_count
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires: executable.name == 'microk8s'
depends: intel_gpu_plugin/labels
_summary: Check that at least one Intel GPU is available on k8s node
estimated_duration: 5s
command: check_intel.sh at_least_one_gpu_is_available

id: intel_gpu_plugin/node_gpu_capacity
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires: executable.name == 'microk8s'
depends: intel_gpu_plugin/gpu_count
_summary: Check that at least expected capacity slots for Intel GPU are availabled
estimated_duration: 5s
command: check_intel.sh capacity_slots_for_gpus_match

id: intel_gpu_plugin/node_gpu_allocatable
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires: executable.name == 'microk8s'
depends: intel_gpu_plugin/node_gpu_capacity
_summary: Check that at least expected allocatable slots for Intel GPU are available
estimated_duration: 5s
command: check_intel.sh allocatable_slots_for_gpus_match

id: dss/status_intel_gpu
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires: executable.name == 'dss'
depends: intel_gpu_plugin/node_gpu_allocatable
_summary: Check that DSS status reports Intel GPU acceleration is enabled
estimated_duration: 5s
command:
  set -eo pipefail
  run_dss.sh status | grep "Intel GPU acceleration: Enabled.*"

id: dss/create_tensorflow_intel_notebook
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires: executable.name == 'dss'
depends: dss/status_intel_gpu
_summary: Check that a Tensorflow Intel notebook can be successfully created
estimated_duration: 5m
command: timeout 5m run_dss.sh create tensorflow-intel --image=tensorflow-intel

id: xpu/tensorflow_can_use_xpu
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires: executable.name == 'kubectl'
depends: dss/create_tensorflow_intel_notebook
_summary: Check that Tensorflow can use XPU in the notebook
estimated_duration: 1m
command: check_notebook.py tensorflow-intel sees_intel_gpu_in_tensorflow

id: dss/remove_tensorflow_intel_notebook
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires: executable.name == 'dss'
depends: dss/create_tensorflow_intel_notebook
_summary: Check that the Tensorflow Intel notebook can be removed
estimated_duration: 1m
command: run_dss.sh remove tensorflow-intel

id: dss/create_pytorch_intel_notebook
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires: executable.name == 'dss'
depends: dss/status_intel_gpu
_summary: Check that a PyTorch Intel notebook can be successfully created
estimated_duration: 5m
command: timeout 5m run_dss.sh create pytorch-intel --image=pytorch-intel

id: xpu/pytorch_can_use_xpu
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires: executable.name == 'kubectl'
depends: dss/create_pytorch_intel_notebook
_summary: Check that Pytorch can use XPU in the notebook
estimated_duration: 1m
command: check_notebook.py pytorch-intel sees_intel_gpu_in_pytorch

id: dss/remove_pytorch_intel_notebook
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires: executable.name == 'dss'
depends: dss/create_pytorch_intel_notebook
_summary: Check that the PyTorch Intel notebook can be removed
estimated_duration: 1m
command: run_dss.sh remove pytorch-intel

# NVIDIA CUDA jobs ############################################################

id: microk8s_nvidia_gpu_addon/enable
category_id: dss-regress
flags: simple
imports:
  from com.canonical.certification import executable
  from com.canonical.certification import graphics_card
requires:
  graphics_card.vendor == 'NVIDIA Corporation'
  executable.name == 'microk8s'
  executable.name == 'kubectl'
depends: dss/initialize
_summary: Enable NVIDIA GPU addon in microk8s
estimated_duration: 10m
command:
  set -eou pipefail
  OPERATOR_VERSION="24.6.2"
  microk8s enable gpu --driver=operator --version="${OPERATOR_VERSION}"
  check_nvidia_gpu_rollout.sh

id: canonical_k8s_nvidia_gpu_operator/install
category_id: dss-regress
flags: simple
imports:
  from com.canonical.certification import executable
  from com.canonical.certification import graphics_card
requires:
  graphics_card.vendor == 'NVIDIA Corporation'
  executable.name == 'k8s'
  executable.name == 'helm'
  executable.name == 'kubectl'
depends: dss/initialize
_summary: Install NVIDIA GPU operator in Canonical k8s
estimated_duration: 10m
command:
  set -eou pipefail
  helm repo add nvidia https://helm.ngc.nvidia.com/nvidia
  helm repo update
  helm install --wait --generate-name -n gpu-operator-resources --create-namespace nvidia/gpu-operator --kubeconfig ~/.kube/config
  check_nvidia_gpu_rollout.sh

id: nvidia_gpu_addon/validations_succeed
category_id: dss-regress
flags: simple
imports:
  from com.canonical.certification import executable
  from com.canonical.certification import graphics_card
requires:
  graphics_card.vendor == 'NVIDIA Corporation'
  executable.name == 'kubectl'
depends: dss/initialize
_summary: NVIDIA GPU validations should succeed
estimated_duration: 10s
command:
  set -eou pipefail
  APP="nvidia-operator-validator"
  logs="$(kubectl -n gpu-operator-resources logs -lapp="$APP" -c "$APP")"
  echo "$logs" | grep "all validations are successful"

id: dss/status_nvidia_gpu
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires: executable.name == 'dss'
depends: nvidia_gpu_addon/validations_succeed
_summary: Check that dss status reports that NVIDIA GPU acceleration is enabled
estimated_duration: 5s
command:
  set -eo pipefail
  run_dss.sh status | grep "NVIDIA GPU acceleration: Enabled.*"

id: dss/create_pytorch_cuda_notebook
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires: executable.name == 'dss'
depends: dss/status_nvidia_gpu
_summary: Check that an PyTorch CUDA notebook can be successfully created
estimated_duration: 5m
command: timeout 5m run_dss.sh create pytorch-cuda --image=pytorch-cuda

id: cuda/pytorch_can_use_cuda
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires: executable.name == 'kubectl'
depends: dss/create_pytorch_cuda_notebook
_summary: Check PyTorch can use CUDA
estimated_duration: 1m
command: check_notebook.py pytorch-cuda sees_nvidia_gpu_in_pytorch

id: dss/remove_pytorch_cuda_notebook
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires: executable.name == 'dss'
depends: dss/create_pytorch_cuda_notebook
_summary: Check that the PyTorch CUDA notebook can be removed
estimated_duration: 1m
command: run_dss.sh remove pytorch-cuda

id: dss/create_tensorflow_cuda_notebook
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires: executable.name == 'dss'
depends: dss/status_nvidia_gpu
_summary: Check that an Tensorflow CUDA notebook can be successfully created
estimated_duration: 5m
command: timeout 5m run_dss.sh create tensorflow-cuda --image=tensorflow-cuda

id: cuda/tensorflow_can_use_cuda
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires: executable.name == 'kubectl'
depends: dss/create_tensorflow_cuda_notebook
_summary: Check Tensorflow can use CUDA
estimated_duration: 1m
command: check_notebook.py tensorflow-cuda sees_nvidia_gpu_in_tensorflow

id: dss/remove_tensorflow_cuda_notebook
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires: executable.name == 'dss'
depends: dss/create_tensorflow_cuda_notebook
_summary: Check that the Tensorflow CUDA notebook can be removed
estimated_duration: 1m
command: run_dss.sh remove tensorflow-cuda

id: dss/purge
category_id: dss-regress
flags: simple
imports: from com.canonical.certification import executable
requires: executable.name == 'dss'
depends: dss/create_tensorflow_cuda_notebook
_summary: Check that DSS can be purged
estimated_duration: 5m
command: timeout 5m run_dss.sh purge
